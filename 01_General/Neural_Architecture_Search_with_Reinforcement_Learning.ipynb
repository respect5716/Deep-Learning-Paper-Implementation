{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Architecture Search with Reinforcement Learning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzh7yGxNDluC",
        "colab_type": "text"
      },
      "source": [
        "# Neural Architecture Search with Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iki6sM3EDsjS",
        "colab_type": "text"
      },
      "source": [
        "## 0. Paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "subFe3E5DttM",
        "colab_type": "text"
      },
      "source": [
        "### Info\n",
        "* TItle : Neural Architecture Search with Reinforcement Learning\n",
        "* Author : Barret Zoph, Quoc V Le\n",
        "* Link : https://arxiv.org/pdf/1611.01578.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvL7j-dcEHBW",
        "colab_type": "text"
      },
      "source": [
        "### Summary\n",
        "* RNN 기반의 control network가 child network의 모델 구조 decoding\n",
        "* child network의 validation accuracy를 reward로 사용\n",
        "* REINFORCE 알고리즘으로 control network 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTR7QXvpDz_j",
        "colab_type": "text"
      },
      "source": [
        "### Features\n",
        "* Skip connection 제외\n",
        "* Search space 축소\n",
        "* child model 메모리 문제 확인 필요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuaQpOWMD9tz",
        "colab_type": "text"
      },
      "source": [
        "## 1. Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZizQk84lEC3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsk7XAE2Lz_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "CONFIG = {\n",
        "    'base_dir' : '/content/drive/Shared drives/Yoon/Project/Doing/Deep Learning Paper Implementation',\n",
        "    'baseline_decay' : 0.9,\n",
        "    'batch_size' : 128,\n",
        "    'epoch_size' : 10,\n",
        "    'step_size' : 30\n",
        "}"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd9D_aouEVMB",
        "colab_type": "text"
      },
      "source": [
        "## 2. Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzYjD0NkEzIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCdnQjRJFn-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype(np.float32) / 255\n",
        "x_test = x_test.astype(np.float32) / 255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoqCydV3wPny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_indices = np.random.permutation(len(x_train))\n",
        "val_indices = random_indices[:5000]\n",
        "train_indices = random_indices[5000:]\n",
        "x_val, y_val = x_train[val_indices], y_train[val_indices]\n",
        "x_train, y_train = x_train[train_indices], y_train[train_indices]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLljDsOoFoLN",
        "colab_type": "text"
      },
      "source": [
        "## 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NbRhIkmFo47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(tf.keras.Model):\n",
        "    def __init__(self, num_layer, search_dict):\n",
        "        super().__init__()\n",
        "        self.num_layer = num_layer\n",
        "        self.search_dict = search_dict\n",
        "        self.search_list = search_dict_to_list(search_dict)\n",
        "        self.key_idx = search_dict_to_key_idx(search_dict)\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(len(self.search_list), 35)\n",
        "        self.lstm1 = tf.keras.layers.LSTM(35, return_sequences=True)\n",
        "        self.lstm2 = tf.keras.layers.LSTM(35)\n",
        "        self.fc = tf.keras.layers.Dense(len(self.search_list))\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.lstm1(x)\n",
        "        x = self.lstm2(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def _decode(self, inputs, key):\n",
        "        inputs = np.array(inputs)\n",
        "        prob = self(inputs)\n",
        "\n",
        "        key_idx = self.key_idx[key]\n",
        "        mask = np.ones((1, len(self.search_list))).astype(np.float32)\n",
        "        mask[0][key_idx[0]:key_idx[1]] = 0.0\n",
        "\n",
        "        prob += mask * -1e7\n",
        "        output = tf.random.categorical(prob, 1)[0][0].numpy()\n",
        "        value = int(self.search_list[output].split('_')[-1])\n",
        "        return output, value\n",
        "    \n",
        "    def decode(self):\n",
        "        inputs = [[0]]\n",
        "        child_model = tf.keras.Sequential()\n",
        "        child_model.add(tf.keras.layers.Input((32, 32, 3)))\n",
        "\n",
        "        for i in range(self.num_layer):\n",
        "            kwargs = {}\n",
        "            for k in self.search_dict.keys():\n",
        "                output, value = self._decode(inputs, k)\n",
        "                inputs[0].append(output)\n",
        "                kwargs[k] = value\n",
        "\n",
        "            layer = output_to_layer(**kwargs)\n",
        "            child_model.add(layer)\n",
        "            child_model.add(tf.keras.layers.MaxPool2D())\n",
        "\n",
        "        child_model.add(tf.keras.layers.Flatten())\n",
        "        child_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "        child_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "        child_model.compile(\n",
        "            loss = 'sparse_categorical_crossentropy',\n",
        "            metrics = ['acc'],\n",
        "            optimizer = tf.keras.optimizers.Adam()\n",
        "        )\n",
        "        inputs = np.array(inputs)\n",
        "        return child_model, inputs\n",
        "        \n",
        "def search_dict_to_list(search_dict):\n",
        "    search_list = ['[START]']\n",
        "    for k, v in search_dict.items():\n",
        "        for _v in v:\n",
        "            search_list.append(f'{k}_{_v}')\n",
        "    return search_list\n",
        "\n",
        "def output_to_layer(filters, kernel_width, kernel_height):\n",
        "    return tf.keras.layers.Conv2D(filters, (kernel_width, kernel_height), padding='same', activation='relu')\n",
        "\n",
        "def search_dict_to_key_idx(search_dict):\n",
        "    key_idx = {}\n",
        "    idx = 1\n",
        "    for k, v in search_dict.items():\n",
        "        key_idx[k] = [idx, idx+len(v)]\n",
        "        idx += len(v)\n",
        "    return key_idx"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeipfpyGt4cp",
        "colab_type": "text"
      },
      "source": [
        "## 4. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xka2QzzZvxxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(model, optimizer, inputs, reward):\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = []\n",
        "        for i in range(1, len(inputs[0])+1):\n",
        "            _inputs = inputs[:,:i]\n",
        "            _prob = model(_inputs)\n",
        "            _loss = -_prob * reward\n",
        "            loss.append(_loss)\n",
        "        loss = tf.reduce_sum(loss)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU2yCK0LOGx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_layer = 5\n",
        "search_dict = {\n",
        "    'filters' : [24, 36],\n",
        "    'kernel_width' : [1, 3, 5],\n",
        "    'kernel_height' : [1, 3, 5],\n",
        "    }\n",
        "\n",
        "model = Model(num_layer, search_dict)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyYWgtsZqAEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseline = 0.0\n",
        "hist = {'loss':[], 'child_acc':[]}\n",
        "\n",
        "for st in range(CONFIG['step_size']):\n",
        "    child_model, inputs = model.decode()\n",
        "    child_model.fit(x_train, y_train, batch_size=CONFIG['batch_size'], epochs=CONFIG['epoch_size'], verbose=0)\n",
        "    child_loss, child_acc = child_model.evaluate(x_val, y_val, batch_size=CONFIG['batch_size'], verbose=0)\n",
        "    \n",
        "    reward = child_acc - baseline\n",
        "    base_line = CONFIG['baseline_decay']*baseline + (1-CONFIG['baseline_decay']) * child_acc\n",
        "    loss = train_step(model, optimizer, inputs, reward)\n",
        "    hist['loss'].append(loss)\n",
        "    hist['child_acc'].append(child_acc)\n",
        "    print(f'STEP : {str(st).zfill(2)} | Loss : {loss:.3f} | Child ACC : {child_acc:.3f}')\n",
        "\n",
        "    K.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhyQw7zyFq8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(13, 7))\n",
        "ax[0].plot(hist['loss'])\n",
        "ax[1].plot(hist['child_acc'])\n",
        "\n",
        "ax[0].set_title('Loss')\n",
        "ax[1].set_title('Child ACC')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owJetCrTFr_S",
        "colab_type": "text"
      },
      "source": [
        "## 5. Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3HN95nRFs-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "child_model, inputs = model.decode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9CWqhaEFtNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "child_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}