{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Collaborative Denoising Auto-Encoders for Top-N Recommender Systems (CDAE).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMEpkzQZ4+a/fc7pKIhg675",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/respect5716/Deep-Learning-Paper-Implementation/blob/master/05_Recommender/Collaborative%20Denoising%20Auto%20Encoders%20for%20Top-N%20Recommender%20Systems%20(CDAE).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzh7yGxNDluC",
        "colab_type": "text"
      },
      "source": [
        "# Collaborative Denoising Auto-Encoders for Top-N Recommender Systems (CDAE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iki6sM3EDsjS",
        "colab_type": "text"
      },
      "source": [
        "## 0. Paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "subFe3E5DttM",
        "colab_type": "text"
      },
      "source": [
        "### Info\n",
        "* TItle : Collaborative Denoising Auto-Encoders for Top-N Recommender Systems (CDAE)\n",
        "* Author : Yao Wu et al.\n",
        "* Publication : WSDM 2016, [link](https://dl.acm.org/doi/pdf/10.1145/2835776.2835837)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvL7j-dcEHBW",
        "colab_type": "text"
      },
      "source": [
        "### Summary\n",
        "* Denoising autoencoder를 추천 시스템에 적용\n",
        "* corrupted input을 복원하도록 학습\n",
        "* user embedding으로 user specific 정보 처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTR7QXvpDz_j",
        "colab_type": "text"
      },
      "source": [
        "### Differences\n",
        "* ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuaQpOWMD9tz",
        "colab_type": "text"
      },
      "source": [
        "## 1. Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HVy-eYPLlUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZizQk84lEC3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw-eONQNEZIl",
        "colab_type": "code",
        "outputId": "60a3eae9-5caf-4f32-a3e7-70220940ae95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# GPU Setting\n",
        "!nvidia-smi\n",
        "\n",
        "print(f'tensorflow version : {tf.__version__}')\n",
        "print(f'available GPU list : {tf.config.list_physical_devices(\"GPU\")}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun  3 08:29:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "tensorflow version : 2.2.0\n",
            "available GPU list : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsk7XAE2Lz_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "CONFIG = {\n",
        "    'base_dir' : '/content/drive/Shared drives/Yoon/Project/Doing/Deep Learning Paper Implementation',\n",
        "    'num_neg' : 5,\n",
        "    'model_dim' : 100,\n",
        "    'learning_rate' : 1e-3,\n",
        "    'corruption_rate' : 0.2,\n",
        "    'lambda' : 0.01, # regularization factor\n",
        "    'batch_size' : 256,\n",
        "    'epoch_size' : 30\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd9D_aouEVMB",
        "colab_type": "text"
      },
      "source": [
        "## 2. Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzYjD0NkEzIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    rating = pd.read_table('data/ratings.dat', sep='::', engine='python', header=None)\n",
        "    rating.columns = ['userId', 'itemId', 'rating', 'timestamp']    \n",
        "    rating = rating.sort_values(['userId', 'timestamp'])\n",
        "    return rating\n",
        "\n",
        "def get_neg_sample(pos, num_item, num_neg=None):\n",
        "    pos = sorted(pos)\n",
        "    \n",
        "    sample = np.arange(0, num_item - len(pos))\n",
        "    pos_adj = pos - np.arange(len(pos))\n",
        "    search = np.searchsorted(pos_adj, sample, side='right')\n",
        "    neg = sample + search\n",
        "\n",
        "    if not num_neg:\n",
        "        num_neg = min(CONFIG['num_neg'] * len(pos), len(neg))\n",
        "    neg = np.random.choice(neg, num_neg)\n",
        "    neg = list(neg)\n",
        "    return neg\n",
        "\n",
        "def multi_hot(seq, num_item):\n",
        "    result = np.zeros(num_item)\n",
        "    result[seq] = 1\n",
        "    return result\n",
        "\n",
        "def corrupt(seq):\n",
        "    corrupted = [i for i in seq if np.random.rand() > CONFIG['corruption_rate']]\n",
        "    if len(corrupted) == 0:\n",
        "        corrupted = [np.random.choice(seq, 1)]\n",
        "    return corrupted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqLcSS3anFAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, train_data, test_data, num_user, num_item, train):\n",
        "        self.train_data = train_data\n",
        "        self.test_data = test_data\n",
        "        self.num_user = num_user\n",
        "        self.num_item = num_item\n",
        "        self.train = train\n",
        "\n",
        "        self.idx = 0 \n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return np.ceil(len(self.train_data) / CONFIG['batch_size']).astype(np.int32)\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.train == 'train':\n",
        "            self.indices = np.random.permutation(len(self.train_data))\n",
        "        else:\n",
        "            self.indices = np.arange(len(self.train_data))\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        batch_idx = self.indices[CONFIG['batch_size']*idx : CONFIG['batch_size']*(idx+1)]\n",
        "        batch_data = self.train_data.iloc[batch_idx]\n",
        "        user = np.array(batch_data.index)\n",
        "        if self.train == 'train':\n",
        "            x = [corrupt(i) for i in batch_data]\n",
        "            x = np.stack([multi_hot(i, self.num_item) for i in x])\n",
        "            pos = np.stack([multi_hot(i, self.num_item) for i in batch_data])\n",
        "            neg = [get_neg_sample(i, self.num_item) for i in batch_data]\n",
        "            neg = np.stack([multi_hot(i, self.num_item) for i in neg])\n",
        "            user, x, pos, neg = user.astype(np.int32), x.astype(np.float32), pos.astype(np.float32), neg.astype(np.float32)\n",
        "        else:\n",
        "            x = np.stack([multi_hot(i, self.num_item) for i in batch_data])\n",
        "            pos = self.test_data.iloc[batch_idx]\n",
        "            neg = None\n",
        "        return user, x, pos, neg\n",
        "\n",
        "    def next(self):\n",
        "        if self.idx == self.__len__():\n",
        "            self.on_epoch_end()\n",
        "            self.idx = 0\n",
        "        user, x, pos, neg = self.__getitem__(self.idx)\n",
        "        self.idx += 1\n",
        "        return user, x, pos, neg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCdnQjRJFn-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = os.path.join(CONFIG['base_dir'], 'data/movielens_10m.zip')\n",
        "!unzip $\"{data_path}\" -d '/content/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGM-wuK9bNCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45BGOrFKbShP",
        "colab_type": "code",
        "outputId": "9137d401-0ac9-46be-a04f-bcf117361f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>itemId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>588</td>\n",
              "      <td>5.0</td>\n",
              "      <td>838983339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>231</td>\n",
              "      <td>5.0</td>\n",
              "      <td>838983392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>316</td>\n",
              "      <td>5.0</td>\n",
              "      <td>838983392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>329</td>\n",
              "      <td>5.0</td>\n",
              "      <td>838983392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>292</td>\n",
              "      <td>5.0</td>\n",
              "      <td>838983421</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    userId  itemId  rating  timestamp\n",
              "18       1     588     5.0  838983339\n",
              "2        1     231     5.0  838983392\n",
              "4        1     316     5.0  838983392\n",
              "5        1     329     5.0  838983392\n",
              "3        1     292     5.0  838983421"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1wULiY7ckr1",
        "colab_type": "code",
        "outputId": "11601bc9-0206-49de-a1e2-b54cd4f53bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "user_dict = data['userId'].unique()\n",
        "user_dict = {j:i for i,j in enumerate(user_dict)}\n",
        "num_user = len(user_dict)\n",
        "\n",
        "item_dict = data['itemId'].unique()\n",
        "item_dict = {j:i for i,j in enumerate(item_dict)}\n",
        "num_item = len(item_dict)\n",
        "\n",
        "num_user, num_item"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69878, 10677)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfobYXM7cIcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.loc[data['rating'] > 3]\n",
        "data['userId'] = data['userId'].map(user_dict)\n",
        "data['itemId'] = data['itemId'].map(item_dict)\n",
        "\n",
        "data = data.groupby('userId')['itemId'].apply(list)\n",
        "data = data.loc[data.apply(len) >= 5]\n",
        "train_data = data.apply(lambda x : x[:int(len(x)*0.8)])\n",
        "test_data = data.apply(lambda x : x[int(len(x)*0.8):])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm-FcjrEce-7",
        "colab_type": "code",
        "outputId": "abf7958a-e429-44d9-9563-e486dd759605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userId\n",
              "0    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
              "2    [41, 42, 40, 44, 45, 47, 48, 49, 50, 51, 52, 5...\n",
              "3    [31, 71, 72, 74, 75, 0, 2, 78, 3, 7, 81, 34, 9...\n",
              "4    [97, 101, 25, 102, 105, 106, 108, 109, 110, 11...\n",
              "5    [175, 33, 176, 178, 180, 22, 181, 182, 183, 18...\n",
              "Name: itemId, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McI_he36jRsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = Dataset(train_data, test_data, num_user, num_item, 'train')\n",
        "test_dataset = Dataset(train_data, test_data, num_user, num_item, 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-ZmCeaTj4ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user, x, pos, neg = train_dataset.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5juWbMVPj6QL",
        "colab_type": "code",
        "outputId": "90a85afa-8329-4b74-ffd1-1cec55780286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "user.shape, x.shape, pos.shape, neg.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((256,), (256, 10677), (256, 10677), (256, 10677))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLljDsOoFoLN",
        "colab_type": "text"
      },
      "source": [
        "## 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NbRhIkmFo47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(tf.keras.Model):\n",
        "    def __init__(self, num_user, num_item):\n",
        "        super(Network, self).__init__()\n",
        "        self.user_embedding = tf.keras.layers.Embedding(num_user, CONFIG['model_dim'])\n",
        "        self.latent_layer = tf.keras.layers.Dense(CONFIG['model_dim'], activation='relu', kernel_regularizer=tf.keras.regularizers.l2(CONFIG['lambda']))\n",
        "        self.output_layer = tf.keras.layers.Dense(num_item, activation='sigmoid')\n",
        "    \n",
        "    def call(self, user, x):\n",
        "        user_embed = self.user_embedding(user)\n",
        "        x = self.latent_layer(x)\n",
        "        x += user_embed\n",
        "        outputs = self.output_layer(x)\n",
        "        return outputs\n",
        "\n",
        "@tf.function\n",
        "def train_step(network, optimizer, user, x, pos, neg):\n",
        "    with tf.GradientTape() as g:\n",
        "        pred = network(user, x)\n",
        "\n",
        "        # square loss function\n",
        "        # pos_loss = tf.reduce_mean(tf.square(pos - pred*pos))\n",
        "        # neg_loss = tf.reduce_mean(tf.square(tf.zeros_like(neg) - pred*neg))\n",
        "        # loss = tf.reduce_mean(pos_loss + neg_loss)\n",
        "\n",
        "        # logistic loss function\n",
        "        pos_loss = pos * tf.math.log(pred + 1e-5)\n",
        "        neg_loss = neg * tf.math.log(1-pred + 1e-5)\n",
        "        loss = -tf.reduce_mean(pos_loss + neg_loss)\n",
        "    \n",
        "    gradient = g.gradient(loss, network.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradient, network.trainable_variables))\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_7_PUNrFpCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network = Network(num_user, num_item)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AILnMW_tFpOG",
        "colab_type": "text"
      },
      "source": [
        "## 4. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0XxhL-uDIbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset.on_epoch_end()\n",
        "for i in tqdm(range(CONFIG['epoch_size'])):\n",
        "    for j in range(len(train_dataset)):\n",
        "        user, x, pos, neg = train_dataset.next()\n",
        "        loss = train_step(network, optimizer, user, x, pos, neg)\n",
        "    \n",
        "    print(f'EP : {str(i).zfill(2)} | loss : {loss:.7f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owJetCrTFr_S",
        "colab_type": "text"
      },
      "source": [
        "## 5. Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA4uO4WyUxGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(true, pred):\n",
        "    return len([i for i in pred if i in true]) / len(pred)\n",
        "\n",
        "def recall(true, pred):\n",
        "    return len([i for i in pred if i in true]) / len(true)\n",
        "\n",
        "def average_precision(true, pred):\n",
        "    avg_prec = np.sum([precision(true, pred[:i+1]) for i in range(len(pred)) if pred[i] in true])\n",
        "    avg_prec /= min(len(true), len(pred))\n",
        "    return avg_prec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-TCy_uHH79c",
        "colab_type": "code",
        "outputId": "484e4589-e76c-4e92-a85e-1586cc30979b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "maps = []\n",
        "test_dataset.on_epoch_end()\n",
        "for i in range(len(test_dataset)):\n",
        "    user, x, pos, _ = test_dataset.next()\n",
        "    pred = network(user, x)\n",
        "    pred = pred * (1-x)\n",
        "    rank = np.argsort(-pred)\n",
        "    batch_maps = [average_precision(i,j[:10]) for i,j in zip(pos, rank)]\n",
        "    maps += batch_maps\n",
        "\n",
        "print(f'MAP@10 : {np.mean(maps):.3f}')"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAP@10 : 0.054\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}