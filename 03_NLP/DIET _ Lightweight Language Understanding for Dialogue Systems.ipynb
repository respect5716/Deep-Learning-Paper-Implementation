{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIET _ Lightweight Language Understanding for Dialogue Systems",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP6cn7OFkEB9D+nKu/Viku6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/respect5716/Deep-Learning-Paper-Implementation/blob/master/03_NLP/DIET%20_%20Lightweight%20Language%20Understanding%20for%20Dialogue%20Systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzh7yGxNDluC",
        "colab_type": "text"
      },
      "source": [
        "# DIET _ Lightweight Language Understanding for Dialogue Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iki6sM3EDsjS",
        "colab_type": "text"
      },
      "source": [
        "## 0. Paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "subFe3E5DttM",
        "colab_type": "text"
      },
      "source": [
        "### Info\n",
        "* TItle : DIET _ Lightweight Language Understanding for Dialogue Systems\n",
        "* Author : Tanja Bunk et al.\n",
        "* Publication : [link](https://arxiv.org/abs/2004.09936)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvL7j-dcEHBW",
        "colab_type": "text"
      },
      "source": [
        "### Summary\n",
        "* Intent Classification과 Entity Recognition을 Multi-tasking하는 Transformer 기반 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTR7QXvpDz_j",
        "colab_type": "text"
      },
      "source": [
        "### Differences\n",
        "* Dataset : NLU Benchmarks -> ATIS, [link](https://www.kaggle.com/siddhadev/atis-dataset-clean/data#)\n",
        "* Featurization : Sparse and Pretrained Dense -> Unpretrained Dense\n",
        "* Loss : Similarity -> Crossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuaQpOWMD9tz",
        "colab_type": "text"
      },
      "source": [
        "## 1. Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HVy-eYPLlUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZizQk84lEC3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Libraries\n",
        "import os\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw-eONQNEZIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "c6d1e56e-67d3-4feb-f1c7-df51f767296d"
      },
      "source": [
        "# GPU Setting\n",
        "!nvidia-smi\n",
        "\n",
        "print(f'tensorflow version : {tf.__version__}')\n",
        "print(f'available GPU list : {tf.config.list_physical_devices(\"GPU\")}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Aug  3 00:20:36 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "tensorflow version : 2.2.0\n",
            "available GPU list : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsk7XAE2Lz_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "CONFIG = {\n",
        "    'base_dir' : '/content/drive/Shared drives/Yoon/Project/Doing/Deep Learning Paper Implementation',\n",
        "    'ffn_dim' : 128,\n",
        "    'model_dim' : 128,\n",
        "    'num_head' : 4,\n",
        "    'num_layer' : 2,\n",
        "    'seq_len' : 30,\n",
        "    'drop_rate' : 0.2,\n",
        "    'batch_size' : 64,\n",
        "    'epoch_size' : 100\n",
        "}"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd9D_aouEVMB",
        "colab_type": "text"
      },
      "source": [
        "## 2. Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFTehC7eg7Wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = os.path.join(CONFIG['base_dir'], 'data/atis.zip')\n",
        "!unzip \"{data_path}\" -d /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWxeUvgQk_U_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a282c3ef-55e5-4d54-e9ea-786f0c7ca6f1"
      },
      "source": [
        "train_data = pd.read_csv('/content/data/atis.train.csv')\n",
        "dev_data = pd.read_csv('/content/data/atis.dev.csv')\n",
        "test_data = pd.read_csv('/content/data/atis.test.csv')\n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tokens</th>\n",
              "      <th>slots</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train-00001</td>\n",
              "      <td>BOS what is the cost of a round trip flight fr...</td>\n",
              "      <td>O O O O O O O B-round_trip I-round_trip O O B-...</td>\n",
              "      <td>atis_airfare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train-00002</td>\n",
              "      <td>BOS now i need a flight leaving fort worth and...</td>\n",
              "      <td>O O O O O O O B-fromloc.city_name I-fromloc.ci...</td>\n",
              "      <td>atis_flight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train-00003</td>\n",
              "      <td>BOS i need to fly from kansas city to chicago ...</td>\n",
              "      <td>O O O O O O B-fromloc.city_name I-fromloc.city...</td>\n",
              "      <td>atis_flight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train-00004</td>\n",
              "      <td>BOS what is the meaning of meal code s EOS</td>\n",
              "      <td>O O O O O O B-meal_code I-meal_code I-meal_code O</td>\n",
              "      <td>atis_abbreviation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train-00005</td>\n",
              "      <td>BOS show me all flights from denver to pittsbu...</td>\n",
              "      <td>O O O O O O B-fromloc.city_name O B-toloc.city...</td>\n",
              "      <td>atis_flight</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  ...             intent\n",
              "0  train-00001  ...       atis_airfare\n",
              "1  train-00002  ...        atis_flight\n",
              "2  train-00003  ...        atis_flight\n",
              "3  train-00004  ...  atis_abbreviation\n",
              "4  train-00005  ...        atis_flight\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul4K6pXSnnR7",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWFPSIddk24O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['tokens'] = train_data['tokens'].apply(lambda x : x.split(' ')[1:-1])\n",
        "dev_data['tokens'] = dev_data['tokens'].apply(lambda x : x.split(' ')[1:-1])\n",
        "test_data['tokens'] = test_data['tokens'].apply(lambda x : x.split(' ')[1:-1])\n",
        "\n",
        "train_data['slots'] = train_data['slots'].apply(lambda x : x.split(' ')[1:-1])\n",
        "dev_data['slots'] = dev_data['slots'].apply(lambda x : x.split(' ')[1:-1])\n",
        "test_data['slots'] = test_data['slots'].apply(lambda x : x.split(' ')[1:-1])\n",
        "\n",
        "train_data['slots'] = train_data['slots'].apply(lambda x : [i.split('-')[1] if '-' in i else i for i in x])\n",
        "dev_data['slots'] = dev_data['slots'].apply(lambda x : [i.split('-')[1] if '-' in i else i for i in x])\n",
        "test_data['slots'] = test_data['slots'].apply(lambda x : [i.split('-')[1] if '-' in i else i for i in x])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry2jN_IBlEm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_vocab = list(set(itertools.chain(*train_data['tokens'])))\n",
        "slot_vocab = list(set(itertools.chain(*train_data['slots'])))\n",
        "intent_vocab = list(set(train_data['intent']))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtJSgcIslkfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_vocab = ['[PAD]', '[CLS]', '[MASK]', '[UNK]'] + token_vocab"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTOBi2KYnpGj",
        "colab_type": "text"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt8kDyk6rJKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, token_vocab, slot_vocab, intent_vocab):\n",
        "        self.token_vocab = token_vocab\n",
        "        self.slot_vocab = slot_vocab\n",
        "        self.intent_vocab = intent_vocab\n",
        "        self.prepare_dict()\n",
        "\n",
        "    def prepare_dict(self):\n",
        "        self.token2id = {j:i for i,j in enumerate(self.token_vocab)}\n",
        "        self.slot2id = {j:i for i,j in enumerate(self.slot_vocab)}\n",
        "        self.intent2id = {j:i for i,j in enumerate(self.intent_vocab)}\n",
        "\n",
        "    def encode_token(self, token):\n",
        "        return [self.token2id.get(i, self.token2id['[UNK]']) for i in token]\n",
        "\n",
        "    def encode_slot(self, slot):\n",
        "        return [self.slot2id[i] for i in slot]\n",
        "\n",
        "    def encode_intent(self, intent):\n",
        "        return self.intent2id[intent]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYiDCOXrpm02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataloader(object):\n",
        "    def __init__(self, data, tokenizer, mode):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.mode = mode\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return np.ceil(len(self.data) / CONFIG['batch_size'])\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        self.idx = 0\n",
        "        if self.mode == 'test':\n",
        "            self.indices = np.arange(len(self.data))\n",
        "        else:\n",
        "            self.indices = np.random.permutation(len(self.data))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_idx = self.indices[CONFIG['batch_size']*idx : CONFIG['batch_size']*(idx+1)]\n",
        "        batch_data = self.data.iloc[batch_idx]\n",
        "        batch_tokens = batch_data['tokens']\n",
        "        batch_masked_tokens = [[self.apply_mask(j) for j in i] for i in batch_tokens]\n",
        "\n",
        "        batch_tokens = [self.tokenizer.encode_token(i) for i in batch_tokens]\n",
        "        batch_tokens = np.array([self.pad_seq(i) for i in batch_tokens])\n",
        "        batch_masked_tokens = [self.tokenizer.encode_token(i) for i in batch_masked_tokens]\n",
        "        batch_masked_tokens = np.array([self.pad_seq(i) for i in batch_masked_tokens])\n",
        "\n",
        "        batch_slots = batch_data['slots']\n",
        "        batch_slots = [self.tokenizer.encode_slot(i) for i in batch_slots]\n",
        "        batch_slots = np.array([self.pad_seq(i, self.tokenizer.slot2id['O']) for i in batch_slots])\n",
        "\n",
        "        batch_intent = batch_data['intent']\n",
        "        batch_intent = [self.tokenizer.encode_intent(i) for i in batch_intent]\n",
        "        batch_intent = np.array(batch_intent)\n",
        "\n",
        "        padding_mask = np.where(batch_tokens==0, 1, 0)[:,None,None,:].astype(np.float32)\n",
        "        mlm_loss_mask = np.where(batch_masked_tokens==2, 1, 0).astype(np.float32)\n",
        "\n",
        "        return batch_masked_tokens, (batch_tokens, batch_slots, batch_intent), (padding_mask, mlm_loss_mask)\n",
        "\n",
        "    def apply_mask(self, token):\n",
        "        r = np.random.rand()\n",
        "        if r < 0.105:\n",
        "            return '[MASK]'\n",
        "        elif r < 0.12:\n",
        "            return self.tokenizer.token_vocab[np.random.randint(5, len(self.tokenizer.token_vocab))]\n",
        "        else:\n",
        "            return token\n",
        "    \n",
        "    def pad_seq(self, seq, value=0):\n",
        "        seq = seq[:CONFIG['seq_len']]\n",
        "        return np.pad(seq, (0, CONFIG['seq_len']-len(seq)), 'constant', constant_values=value)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0w5VyWVn0yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(token_vocab, slot_vocab, intent_vocab)\n",
        "train_loader = Dataloader(train_data, tokenizer, 'train')"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY1ndoTro6cW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12972994-1ed3-45b2-c7d9-cde3d52c9172"
      },
      "source": [
        "x, y, mask = train_loader.__getitem__(1)\n",
        "x.shape, y[0].shape, y[1].shape, mask[0].shape, mask[1].shape"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((64, 30), (64, 30), (64, 30), (64, 1, 1, 30), (64, 30))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLljDsOoFoLN",
        "colab_type": "text"
      },
      "source": [
        "## 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NbRhIkmFo47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)\n",
        "\n",
        "def gelu(x):\n",
        "    cdf = 0.5 * (1.0 + tf.math.erf(x / tf.sqrt(2.0)))\n",
        "    return x * cdf\n",
        "\n",
        "\n",
        "class Embedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, token_vocab_size):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.token_embedding = tf.keras.layers.Embedding(token_vocab_size, CONFIG['model_dim'])\n",
        "        self.position_embedding = tf.keras.layers.Embedding(CONFIG['seq_len'], CONFIG['model_dim'])\n",
        "        self.pos = tf.range(0, CONFIG['seq_len'])\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.token_embedding(x)\n",
        "        pos = self.position_embedding(self.pos)\n",
        "        x += pos\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, model_dim, num_head):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.model_dim = model_dim\n",
        "        self.num_head = num_head\n",
        "        self.projection_dim = self.model_dim // self.num_head\n",
        "        assert self.model_dim % self.num_head == 0\n",
        "\n",
        "        self.qw = tf.keras.layers.Dense(self.model_dim)\n",
        "        self.kw = tf.keras.layers.Dense(self.model_dim)\n",
        "        self.vw = tf.keras.layers.Dense(self.model_dim)\n",
        "        self.w = tf.keras.layers.Dense(self.model_dim)\n",
        "    \n",
        "    def attention(self, q, k ,v, mask):\n",
        "        dim = tf.cast(tf.shape(q)[-1], tf.float32)\n",
        "        score = tf.matmul(q, k, transpose_b=True)\n",
        "        scaled_score = score / tf.math.sqrt(dim)\n",
        "\n",
        "        if mask is not None:\n",
        "            scaled_score += (mask * -1e9)\n",
        "\n",
        "        attention_weights = tf.nn.softmax(scaled_score)\n",
        "        attention_outputs = tf.matmul(attention_weights, v)\n",
        "        return attention_outputs, attention_weights\n",
        "    \n",
        "    def split_heads(self, x):\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_head, self.projection_dim))\n",
        "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        return x\n",
        "    \n",
        "    def combine_heads(self, x):\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        x = tf.reshape(x, (batch_size, -1, self.model_dim))\n",
        "        return x\n",
        "    \n",
        "    def call(self, q, k, v, mask):\n",
        "        q, k, v = self.qw(q), self.kw(k), self.vw(v)\n",
        "        q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
        "        outputs, weights = self.attention(q, k, v, mask)\n",
        "        outputs = self.combine_heads(outputs)\n",
        "        outputs = self.w(outputs)\n",
        "        return outputs\n",
        "\n",
        "class FeedForwardNetwork(tf.keras.layers.Layer):\n",
        "    def __init__(self, model_dim, ffn_dim):\n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(ffn_dim)\n",
        "        self.dense2 = tf.keras.layers.Dense(model_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.dense1(x)\n",
        "        x = gelu(x)\n",
        "        x = self.dense2(x)\n",
        "        return x\n",
        "\n",
        "class TransformerLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(TransformerLayer, self).__init__()\n",
        "        self.mha = MultiHeadAttention(CONFIG['model_dim'], CONFIG['num_head'])\n",
        "        self.ffn = FeedForwardNetwork(CONFIG['model_dim'], CONFIG['ffn_dim'])\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(CONFIG['drop_rate'])\n",
        "        self.dropout2 = tf.keras.layers.Dropout(CONFIG['drop_rate'])\n",
        "\n",
        "    def call(self, x, training, mask=None):\n",
        "        out1 = self.mha(x, x, x, mask)\n",
        "        out1 = self.dropout1(out1, training=training)\n",
        "        out1 = self.layernorm1(x + out1)\n",
        "        out2 = self.ffn(out1)\n",
        "        out2 = self.dropout2(out2, training=training)\n",
        "        out2 = self.layernorm2(out1 + out2)\n",
        "        return out2\n",
        "\n",
        "class CRFLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_tag):\n",
        "        super(CRFLayer, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(num_tag)\n",
        "        self.transition_params = None\n",
        "\n",
        "    def call(self, x, y, mask):\n",
        "        shape = mask[:,0,0,:].sum(axis=-1)\n",
        "        x = self.dense(x)\n",
        "        outputs, self.transition_params = tfa.text.crf_log_likelihood(x, y, shape)\n",
        "        preds, _ = tfa.text.crf.crf_decode(x, self.transition_params, shape)\n",
        "        return outputs, preds\n",
        "\n",
        "class Network(tf.keras.Model):\n",
        "    def __init__(self, token_size, slot_size, intent_size):\n",
        "        super(Network, self).__init__()\n",
        "        self.embedding = Embedding(token_size)\n",
        "        self.transformers = [TransformerLayer() for _ in range(CONFIG['num_layer'])]\n",
        "        self.mlm_outputs = tf.keras.layers.Dense(token_size, activation='softmax')\n",
        "        self.slot_outputs = CRFLayer(slot_size)\n",
        "        self.intent_outputs = tf.keras.layers.Dense(intent_size, activation='softmax')\n",
        "        self.optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        x, y, (padding_mask, mlm_loss_mask) = inputs\n",
        "        x = self.embedding(x)\n",
        "        for trm in self.transformers:\n",
        "            x = trm(x, mask=padding_mask, training=training)\n",
        "        mlm = self.mlm_outputs(x)\n",
        "        slot, slot_pred = self.slot_outputs(x, y[1], mask[0])\n",
        "        intent = self.intent_outputs(x[:,-1])\n",
        "        return mlm, intent, slot, slot_pred"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPi_A3FyxA4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_size = len(tokenizer.token_vocab)\n",
        "slot_size = len(tokenizer.slot_vocab)\n",
        "intent_size = len(tokenizer.intent_vocab)"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9HDgLNuIsn0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "46949926-29ec-4bc0-c661-c44680ebffd6"
      },
      "source": [
        "network = Network(token_size, slot_size, intent_size)\n",
        "network.summary()"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"network_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_69 (Embedding)     multiple                  115968    \n",
            "_________________________________________________________________\n",
            "transformer_layer_46 (Transf multiple                  99584     \n",
            "_________________________________________________________________\n",
            "transformer_layer_47 (Transf multiple                  99584     \n",
            "_________________________________________________________________\n",
            "dense_356 (Dense)            multiple                  113004    \n",
            "_________________________________________________________________\n",
            "crf_layer_23 (CRFLayer)      multiple                  13396     \n",
            "_________________________________________________________________\n",
            "dense_358 (Dense)            multiple                  2193      \n",
            "=================================================================\n",
            "Total params: 443,729\n",
            "Trainable params: 443,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AILnMW_tFpOG",
        "colab_type": "text"
      },
      "source": [
        "## 4. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA5egD6I1Tri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(network, data):\n",
        "    x, y, mask = data\n",
        "\n",
        "    with tf.GradientTape() as g:\n",
        "        mlm, intent, slot, _ = network((x, y, mask), True)\n",
        "        mlm_loss = tf.keras.losses.sparse_categorical_crossentropy(y[0], mlm)\n",
        "        mlm_loss = tf.reduce_mean(mlm_loss * mask[1])\n",
        "        slot_loss = tf.reduce_sum(-slot) / tf.cast(x.shape[0], tf.float32)\n",
        "        intent_loss = tf.keras.losses.sparse_categorical_crossentropy(y[2], intent)\n",
        "        intent_loss = tf.reduce_mean(intent_loss)\n",
        "        total_loss = mlm_loss + slot_loss + intent_loss\n",
        "        \n",
        "    gradients = g.gradient(total_loss, network.trainable_variables)\n",
        "    network.optimizer.apply_gradients(zip(gradients, network.trainable_variables))\n",
        "    return {'total':total_loss, 'mlm':mlm_loss, 'slot':slot_loss, 'intent':intent_loss}"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCpTqodKFrwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "dd612aae-5fb0-4805-9f77-74021a049915"
      },
      "source": [
        "for ep in range(CONFIG['epoch_size']):\n",
        "    for step, data in enumerate(train_loader):\n",
        "        if len(data[0]) != CONFIG['batch_size']:\n",
        "            continue\n",
        "        loss = train_step(network, data)\n",
        "\n",
        "    if ep % 10 == 0:\n",
        "        print(f\"EP : {str(ep).zfill(3)} | Total : {loss['total'].numpy():.3f} | MLM : {loss['mlm'].numpy():.3f} | Intent : {loss['intent'].numpy():.3f} | Slot : {loss['slot'].numpy():.3f}\")\n",
        "\n",
        "print(f\"EP : {str(ep+1).zfill(3)} | Total : {loss['total'].numpy():.3f} | MLM : {loss['mlm'].numpy():.3f} | Intent : {loss['intent'].numpy():.3f} | Slot : {loss['slot'].numpy():.3f}\")"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EP : 000 | Total : 6.383 | MLM : 0.178 | Intent : 0.826 | Slot : 5.380\n",
            "EP : 010 | Total : 1.218 | MLM : 0.104 | Intent : 0.210 | Slot : 0.903\n",
            "EP : 020 | Total : 0.510 | MLM : 0.109 | Intent : 0.064 | Slot : 0.336\n",
            "EP : 030 | Total : 0.904 | MLM : 0.112 | Intent : 0.025 | Slot : 0.767\n",
            "EP : 040 | Total : 0.810 | MLM : 0.101 | Intent : 0.109 | Slot : 0.600\n",
            "EP : 050 | Total : 0.881 | MLM : 0.128 | Intent : 0.088 | Slot : 0.665\n",
            "EP : 060 | Total : 0.977 | MLM : 0.097 | Intent : 0.057 | Slot : 0.822\n",
            "EP : 070 | Total : 0.548 | MLM : 0.079 | Intent : 0.022 | Slot : 0.446\n",
            "EP : 080 | Total : 0.287 | MLM : 0.070 | Intent : 0.055 | Slot : 0.162\n",
            "EP : 090 | Total : 0.417 | MLM : 0.079 | Intent : 0.012 | Slot : 0.326\n",
            "EP : 100 | Total : 0.441 | MLM : 0.061 | Intent : 0.011 | Slot : 0.369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owJetCrTFr_S",
        "colab_type": "text"
      },
      "source": [
        "## 5. Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v04D8u8v3X65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_step(network, data):\n",
        "    x, y, mask = data\n",
        "    mlm, intent, _, slot = network((x, y, mask), False)\n",
        "    \n",
        "    mlm_acc = y[0] == np.argmax(mlm, axis=-1)\n",
        "    mlm_acc = np.sum(mlm_acc * mask[1]) / np.sum(mask[1])\n",
        "\n",
        "    slot_acc = tf.cast((slot == y[1]), tf.int32)\n",
        "    slot_mask = (1- mask[0][:,0,0,:])\n",
        "    slot_acc = np.sum(slot_acc * slot_mask) / np.sum(slot_mask)\n",
        "\n",
        "    intent_acc = y[2] == np.argmax(intent, axis=-1)\n",
        "    intent_acc = np.mean(intent_acc)\n",
        "    return mlm_acc, slot_acc, intent_acc"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3HN95nRFs-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader = Dataloader(test_data, tokenizer, 'test')"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9CWqhaEFtNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "953f6dbe-e4a6-4046-f1dd-36d83b475996"
      },
      "source": [
        "acc = {'mlm':[], 'slot':[], 'intent':[]}\n",
        "for step, data in enumerate(test_loader):\n",
        "    if len(data[0]) != CONFIG['batch_size']:\n",
        "        break\n",
        "        \n",
        "    mlm_acc, slot_acc, intent_acc = test_step(network, data)\n",
        "    acc['mlm'].append(mlm_acc)\n",
        "    acc['slot'].append(slot_acc)\n",
        "    acc['intent'].append(intent_acc)\n",
        "\n",
        "print(f\"MLM : {np.mean(acc['mlm']):.3f} | Intent : {np.mean(acc['intent']):.3f} | Slot : {np.mean(acc['slot']):.3f}\")"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLM : 0.582 | Intent : 0.969 | Slot : 0.940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLBsuMqQHcEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}