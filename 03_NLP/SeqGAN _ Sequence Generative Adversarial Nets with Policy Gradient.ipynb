{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeqGAN _ Sequence Generative Adversarial Nets with Policy Gradient.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNRq038q5r/eGiySogoCWJc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/respect5716/Deep-Learning-Paper-Implementation/blob/master/03_NLP/SeqGAN%20_%20Sequence%20Generative%20Adversarial%20Nets%20with%20Policy%20Gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzh7yGxNDluC",
        "colab_type": "text"
      },
      "source": [
        "# SeqGAN _ Sequence Generative Adversarial Nets with Policy Gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iki6sM3EDsjS",
        "colab_type": "text"
      },
      "source": [
        "## 0. Paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "subFe3E5DttM",
        "colab_type": "text"
      },
      "source": [
        "### Info\n",
        "* TItle : SeqGAN _ Sequence Generative Adversarial Nets with Policy Gradient\n",
        "* Author : Lantao Yu et al.\n",
        "* Publication : AAAI 2017"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvL7j-dcEHBW",
        "colab_type": "text"
      },
      "source": [
        "### Summary\n",
        "* GAN과 Policy gradient를 사용하여 discrete sequence 생성 모델 학습\n",
        "* 완전히 생성된 문장을 평가함으로써 더욱 사실적인 문장 생성 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTR7QXvpDz_j",
        "colab_type": "text"
      },
      "source": [
        "### Differences\n",
        "* Dataset : political speech -> Naver sentiment movie corpus, [link](https://github.com/e9t/nsmc/)\n",
        "* Pretrain : True -> False\n",
        "* Discriminator highway network : True -> False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuaQpOWMD9tz",
        "colab_type": "text"
      },
      "source": [
        "## 1. Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0obIg_SKE5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install mecab and konlpy\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git /content/mecab\n",
        "!bash mecab/install_mecab-ko_on_colab190912.sh\n",
        "!pip install -q konlpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HVy-eYPLlUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZizQk84lEC3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import Counter\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw-eONQNEZIl",
        "colab_type": "code",
        "outputId": "4ab340aa-12d8-4604-b41d-d4bade809f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# GPU Setting\n",
        "!nvidia-smi\n",
        "\n",
        "print(f'tensorflow version : {tf.__version__}')\n",
        "print(f'available GPU list : {tf.config.list_physical_devices(\"GPU\")}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun  1 12:47:20 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "tensorflow version : 2.2.0\n",
            "available GPU list : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsk7XAE2Lz_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "CONFIG = {\n",
        "    'base_dir' : '/content/drive/Shared drives/Yoon/Project/Doing/Deep Learning Paper Implementation',\n",
        "    'seq_len' : 16,\n",
        "    'model_dim' : 128,\n",
        "    'generator_lr' : 1e-3,\n",
        "    'discriminator_lr' : 1e-3,\n",
        "    'neg_ratio' : 3,\n",
        "    'g_step_size' : 2,\n",
        "    'd_step_size' : 5,\n",
        "    'd_epoch_size' : 2,\n",
        "    'batch_size' : 64,\n",
        "    'epoch_size' : 100\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd9D_aouEVMB",
        "colab_type": "text"
      },
      "source": [
        "## 2. Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzYjD0NkEzIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = os.path.join(CONFIG['base_dir'], 'data/naver_sentiment_movie_corpus.zip')\n",
        "!unzip $\"{data_path}\" -d '/content/data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCdnQjRJFn-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_table('/content/data/ratings_train.txt')\n",
        "test_data = pd.read_table('/content/data/ratings_test.txt')\n",
        "\n",
        "train_data = train_data.dropna()\n",
        "test_data = test_data.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnOxgSOmLBPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mecab = Mecab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBxt2t-adQof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['document'] = train_data['document'].apply(lambda x : x.replace('/', ' ').replace(' ', '_'))\n",
        "train_data['token'] = train_data['document'].apply(lambda x : ['/'.join(i) for i in mecab.pos(x)])\n",
        "train_data['label'] = train_data['label'].map({0:'[NEG]', 1:'[POS]'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-RdpPsPd5lr",
        "colab_type": "code",
        "outputId": "6e45d1e3-e2f5-41f9-a88c-9e5825004e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab = Counter()\n",
        "_ = [vocab.update(i) for i in train_data['token']]\n",
        "\n",
        "vocab = [i for i in vocab if vocab[i] >= 10]\n",
        "vocab = ['[PAD]', '[UNK]', '[EOS]', '[POS]', '[NEG]'] + vocab\n",
        "\n",
        "len(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11757"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7wuEgqN9Mfu",
        "colab_type": "code",
        "outputId": "551137ac-cd97-40a5-a0bb-df8c4543c6cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "      <th>token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아_더빙.._진짜_짜증나네요_목소리</td>\n",
              "      <td>[NEG]</td>\n",
              "      <td>[아/IC, _/SY, 더/MAG, 빙/MAG, ./SF, ._/SY, 진짜/MAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고_초딩영화줄....오버연기조차_가볍지_않구나</td>\n",
              "      <td>[POS]</td>\n",
              "      <td>[흠/IC, ./SF, ../SY, 포스터/NNP, 보고/NNG, _/SY, 초딩/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>[NEG]</td>\n",
              "      <td>[너무/MAG, 재/XPN, 밓었다그래서보는것을추천한다/UNKNOWN]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소_이야기구먼_..솔직히_재미는_없다..평점_조정</td>\n",
              "      <td>[NEG]</td>\n",
              "      <td>[교도소/NNG, _/SY, 이야기/NNG, 구먼/VCP+EF, _../SY, 솔직...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의_익살스런_연기가_돋보였던_영화!스파이더맨에서_늙어보이기만_했던_커스틴_...</td>\n",
              "      <td>[POS]</td>\n",
              "      <td>[사이몬페그/NNP, 의/JKG, _/SY, 익살/NNG, 스런/XSA+ETM, _...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...                                              token\n",
              "0   9976970  ...  [아/IC, _/SY, 더/MAG, 빙/MAG, ./SF, ._/SY, 진짜/MAG...\n",
              "1   3819312  ...  [흠/IC, ./SF, ../SY, 포스터/NNP, 보고/NNG, _/SY, 초딩/...\n",
              "2  10265843  ...            [너무/MAG, 재/XPN, 밓었다그래서보는것을추천한다/UNKNOWN]\n",
              "3   9045019  ...  [교도소/NNG, _/SY, 이야기/NNG, 구먼/VCP+EF, _../SY, 솔직...\n",
              "4   6483659  ...  [사이몬페그/NNP, 의/JKG, _/SY, 익살/NNG, 스런/XSA+ETM, _...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLljDsOoFoLN",
        "colab_type": "text"
      },
      "source": [
        "## 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-lOxu1gPfIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_seq(seq):\n",
        "    seq = [i[:CONFIG['seq_len']] for i in seq]\n",
        "    seq = np.stack([np.pad(i, (0, CONFIG['seq_len']-len(i)), 'constant') for i in seq])\n",
        "    return seq\n",
        "\n",
        "def generate_init_state():\n",
        "    if np.random.rand() < 0.5:\n",
        "        token = np.array([[3]]) # [POS]\n",
        "    else:\n",
        "        token = np.array([[4]]) # [NEG]\n",
        "    state_h = np.random.normal(size=(1, CONFIG['model_dim']))\n",
        "    state_c = np.random.normal(size=(1, CONFIG['model_dim']))\n",
        "    return token, state_h, state_c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLozt1BifkNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, tagger, vocab):\n",
        "        self.tagger = tagger\n",
        "        self.vocab = vocab\n",
        "        self.token2idx = {j:i for i,j in enumerate(vocab)}\n",
        "        self.idx2token = {i:j for i,j in enumerate(vocab)}\n",
        "        self.vocab_size = len(vocab)\n",
        "    \n",
        "    def seq_to_idx(self, seq):\n",
        "        return [self.token2idx[i] if i in self.vocab else self.token2idx['[UNK]'] for i in seq]\n",
        "    \n",
        "    def encode(self, sentence):\n",
        "        sentence = sentence.replace('/', ' ').replace(' ', '_')\n",
        "        tokens = self.tagger.pos(sentence)\n",
        "        tokens = ['/'.join(i) for i in tokens]\n",
        "        tokens = seq_to_idx(tokens)\n",
        "        return tokens\n",
        "    \n",
        "    def decode(self, tokens):\n",
        "        tokens = [self.idx2token[i] for i in tokens]\n",
        "        tokens = [i.split('/')[0] for i in tokens]\n",
        "        sentence = ''.join(tokens)\n",
        "        sentence = sentence.replace('_', ' ')\n",
        "        return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKbamI0Z4W-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrueDataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.data_len = len(data)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.idx = 0\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return np.ceil(len(self.data) / CONFIG['batch_size']).astype(np.int32)\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        self.indices = np.random.permutation(self.data_len)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_idx = self.indices[CONFIG['batch_size']*idx : CONFIG['batch_size']*(idx+1)]\n",
        "        x = self.data.iloc[batch_idx].apply(lambda x : [x['label']] + x['token'], axis=1)\n",
        "        x = [i[:CONFIG['seq_len']] + ['[EOS]'] if len(i) < CONFIG['seq_len'] else i[:CONFIG['seq_len']-1] + ['[EOS]'] for i in x]\n",
        "        x = [self.tokenizer.seq_to_idx(i) for i in x]\n",
        "        x = np.stack(pad_seq(x))\n",
        "        y = np.ones(CONFIG['batch_size'])\n",
        "        return x, y\n",
        "    \n",
        "    def next(self):\n",
        "        if self.idx == self.__len__():\n",
        "            self.on_epoch_end()\n",
        "            self.idx = 0\n",
        "        x, y = self.__getitem__(self.idx)\n",
        "        self.idx += 1\n",
        "        return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NbRhIkmFo47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(object):\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.network, self.optimizer = self.build_network()\n",
        "    \n",
        "    def build_network(self):\n",
        "        input_token = tf.keras.Input(shape=(None,))\n",
        "        input_state_h = tf.keras.Input(shape=(CONFIG['model_dim'],))\n",
        "        input_state_c = tf.keras.Input(shape=(CONFIG['model_dim'],))\n",
        "        embed_token = tf.keras.layers.Embedding(self.tokenizer.vocab_size, CONFIG['model_dim'])(input_token)\n",
        "        x, state_h, state_c = tf.keras.layers.LSTM(CONFIG['model_dim'], return_state=True)(embed_token, initial_state=[input_state_h, input_state_c])\n",
        "        output_token = tf.keras.layers.Dense(self.tokenizer.vocab_size, activation='softmax')(x)\n",
        "\n",
        "        network = tf.keras.Model([input_token, input_state_h, input_state_c], [output_token, state_h, state_c])\n",
        "        optimizer = tf.keras.optimizers.Adam(CONFIG['generator_lr'])\n",
        "        return network, optimizer\n",
        "    \n",
        "    def write_token(self, token, state_h, state_c):\n",
        "        token, state_h, state_c = self.network([token, state_h, state_c])\n",
        "        token = tf.random.categorical(token, 1).numpy() # (1, 1)\n",
        "        return token, state_h, state_c\n",
        "    \n",
        "    def write_sentence(self, token, state_h, state_c):\n",
        "        sentence = list(token[0])\n",
        "        while token[0][0] != self.tokenizer.token2idx['[EOS]'] and len(sentence) < CONFIG['seq_len']:\n",
        "            token, state_h, state_c = self.write_token(token, state_h, state_c)\n",
        "            word = token[0][0]\n",
        "            sentence.append(word)\n",
        "        return sentence\n",
        "    \n",
        "    def write_sentence_init(self):\n",
        "        token, state_h, state_c = generate_init_state()\n",
        "        sentence = self.write_sentence(token, state_h, state_c)\n",
        "        return sentence\n",
        "\n",
        "    def train(self, token, state_h, state_c, next_token, reward):\n",
        "        with tf.GradientTape() as g:\n",
        "            policy, state_h, state_c = self.network([token, state_h, state_c])\n",
        "            policy = tf.reduce_sum(policy * tf.one_hot(next_token, depth=self.tokenizer.vocab_size), axis=-1)\n",
        "            loss = -tf.reduce_mean(policy * reward)\n",
        "        \n",
        "        gradients = g.gradient(loss, self.network.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_variables))       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "davLOwKtpO0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(object):\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.network = self.build_network()\n",
        "    \n",
        "    def build_network(self):\n",
        "        inputs = tf.keras.layers.Input((CONFIG['seq_len'],))\n",
        "        x = tf.keras.layers.Embedding(self.tokenizer.vocab_size, CONFIG['model_dim'])(inputs)\n",
        "        x = tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu')(x)\n",
        "        x = tf.keras.layers.MaxPool1D(2)(x)\n",
        "        x = tf.keras.layers.Conv1D(64, 3, padding='same', activation='relu')(x)\n",
        "        x = tf.keras.layers.MaxPool1D(2)(x)\n",
        "        x = tf.keras.layers.Conv1D(128, 3, padding='same', activation='relu')(x)\n",
        "        x = tf.keras.layers.MaxPool1D(2)(x)\n",
        "        x = tf.keras.layers.Conv1D(256, 3, padding='same', activation='relu')(x)\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "        x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "        \n",
        "        network = tf.keras.Model(inputs, outputs)\n",
        "        network.compile(\n",
        "            loss = 'binary_crossentropy',\n",
        "            optimizer = tf.keras.optimizers.Adam(CONFIG['discriminator_lr']),\n",
        "            metrics = ['acc']\n",
        "        )\n",
        "        return network\n",
        "    \n",
        "    def give_reward(self, x):\n",
        "        return tf.round(self.network(x)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AILnMW_tFpOG",
        "colab_type": "text"
      },
      "source": [
        "## 4. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhyQw7zyFq8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(mecab, vocab)\n",
        "generator = Generator(tokenizer)\n",
        "discriminator = Discriminator(tokenizer)\n",
        "dataset = TrueDataset(train_data, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "564uSNE41W5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ep in range(CONFIG['epoch_size']):\n",
        "    for g in range(CONFIG['g_step_size']):\n",
        "        token, state_h, state_c = generate_init_state()\n",
        "        sentence = generator.write_sentence(token, state_h, state_c)\n",
        "\n",
        "        for i in range(1, len(sentence)):\n",
        "            subsentence = np.array([sentence[:i]])\n",
        "            next_token = sentence[i]\n",
        "\n",
        "            if i < len(sentence):\n",
        "                generated = [generator.write_sentence(subsentence, state_h, state_c) for _ in range(CONFIG['batch_size'])]\n",
        "                generated = np.stack(pad_seq(generated))\n",
        "                reward = np.mean(discriminator.give_reward(generated))\n",
        "            else:\n",
        "                reward = discriminator.give_reward(np.array([sentence]))\n",
        "                reward = np.array([reward])\n",
        "\n",
        "            generator.train(subsentence, state_h, state_c, next_token, reward)\n",
        "\n",
        "    for d in range(CONFIG['d_step_size']):\n",
        "        x_true, y_true = dataset.next()\n",
        "        x_false = [generator.write_sentence_init() for _ in range(CONFIG['batch_size'] * CONFIG['neg_ratio'])]\n",
        "        x_false = pad_seq(x_false)\n",
        "        y_false = np.zeros(CONFIG['batch_size'] * CONFIG['neg_ratio'])\n",
        "        x = np.append(x_true, x_false, axis=0)\n",
        "        y = np.append(y_true, y_false, axis=0)\n",
        "        discriminator.network.fit(x, y, batch_size=CONFIG['batch_size'], epochs=CONFIG['d_epoch_size'], verbose=0)\n",
        "    \n",
        "    sentence = tokenizer.decode(sentence)\n",
        "    print(f'EP : {str(ep).zfill(3)} | Reward : {str(int(reward.sum())).zfill(3)} | Sentence : {sentence}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owJetCrTFr_S",
        "colab_type": "text"
      },
      "source": [
        "## 5. Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtPk45nvVnaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data['document'] = test_data['document'].apply(lambda x : x.replace('/', ' ').replace(' ', '_'))\n",
        "test_data['token'] = test_data['document'].apply(lambda x : ['/'.join(i) for i in mecab.pos(x)])\n",
        "test_data['label'] = test_data['label'].map({0:'[NEG]', 1:'[POS]'})\n",
        "test_dataset = TrueDataset(test_data, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c-EwLssV22c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_true, y_true = test_dataset.next()\n",
        "x_false = [generator.write_sentence_init() for _ in range(CONFIG['batch_size'])]\n",
        "x_false = pad_seq(x_false)\n",
        "y_false = np.zeros(CONFIG['batch_size'])\n",
        "x = np.append(x_true, x_false, axis=0)\n",
        "y = np.append(y_true, y_false, axis=0)\n",
        "\n",
        "loss, acc = discriminator.network.evaluate(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GERFdEQiVRiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10):\n",
        "    sentence = generator.write_sentence_init()\n",
        "    sentence = tokenizer.decode(sentence)\n",
        "    print(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jetWtzWwW9O1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}